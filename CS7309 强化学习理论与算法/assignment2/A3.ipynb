{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_height, world_width = 5, 10\n",
    "epsilon = 0.0000001\n",
    "alpha = 0.2\n",
    "gamma = 0.5\n",
    "epochs = 10000\n",
    "start_pos, end_pos = (world_height-1, 0), (world_height-1, world_width-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_action(pos, policy, epsilon=0) -> int:\n",
    "    validActionList = [0, 1, 2, 3]\n",
    "    if pos[0]==0:\n",
    "        validActionList.remove(0)\n",
    "    if pos[0]==world_height-1:\n",
    "        validActionList.remove(1)\n",
    "    if pos[1]==0:\n",
    "        validActionList.remove(2)\n",
    "    if pos[1]==world_width-1:\n",
    "        validActionList.remove(3)\n",
    "\n",
    "    if np.random.uniform(0, 1) <= epsilon:\n",
    "        return random.sample(validActionList, 1)[0]\n",
    "    else:\n",
    "        # check validity\n",
    "        if np.argmax(policy[pos[0]][pos[1]]) in validActionList:\n",
    "            return np.argmax(policy[pos[0]][pos[1]])\n",
    "        else:\n",
    "            return random.sample(validActionList, 1)[0]\n",
    "        \n",
    "# 这里不check是否在cliff导致返回start_pos\n",
    "def next_pos(pos, action) -> tuple:\n",
    "    if action == 0:\n",
    "        return (pos[0]-1, pos[1])\n",
    "    if action == 1:\n",
    "        return (pos[0]+1, pos[1])\n",
    "    if action == 2:\n",
    "        return (pos[0], pos[1]-1)\n",
    "    if action == 3:\n",
    "        return (pos[0], pos[1]+1)\n",
    "    \n",
    "def get_reward(pos) -> int:\n",
    "    if pos == end_pos:\n",
    "        return -1\n",
    "    if pos[0] == world_height-1:\n",
    "        return -100\n",
    "    return -1\n",
    "\n",
    "def show_policy(policy):\n",
    "    current_pos = start_pos\n",
    "    episode = [current_pos]\n",
    "    while current_pos != end_pos:\n",
    "        step_action = next_action(current_pos, policy)\n",
    "        step_pos = next_pos(current_pos, step_action)\n",
    "        if step_pos[0] == world_height-1 and 0 < step_pos[1] < world_width-1:\n",
    "            step_pos = start_pos\n",
    "        current_pos = step_pos\n",
    "        if current_pos in episode:\n",
    "            print(\"fail\\n\")\n",
    "            break\n",
    "        episode.append(current_pos)\n",
    "    if current_pos == end_pos:\n",
    "        for pos in episode[:-1]:\n",
    "            print(pos, end='->')\n",
    "        pos = episode[-1]\n",
    "        print(pos)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sarsa(epochs):\n",
    "    Q_matrix = [[[0.0 for _ in range(4)] for _ in range(world_width)] for _ in range(world_height)]\n",
    "    for row in range(world_height):\n",
    "        for column in range(world_width):\n",
    "            if row==0:\n",
    "                Q_matrix[row][column][0] = -sys.maxsize - 1\n",
    "            if row==world_height-1:\n",
    "                Q_matrix[row][column][1] = -sys.maxsize - 1\n",
    "            if column==0:\n",
    "                Q_matrix[row][column][2] = -sys.maxsize - 1\n",
    "            if column==world_width-1:\n",
    "                Q_matrix[row][column][3] = -sys.maxsize - 1\n",
    "    for epoch in range(epochs):\n",
    "        current_pos = start_pos\n",
    "        while current_pos != end_pos:\n",
    "            step_action = next_action(current_pos, Q_matrix, epsilon)\n",
    "            step_pos = next_pos(current_pos, step_action)\n",
    "            step_reward = get_reward(step_pos)\n",
    "            if step_pos[0] == world_height-1 and 0 < step_pos[1] < world_width-1:\n",
    "                step_pos = start_pos\n",
    "            forsee_action = next_action(step_pos, Q_matrix, epsilon)\n",
    "            Q_matrix[current_pos[0]][current_pos[1]][step_action] += alpha * (step_reward + gamma * Q_matrix[step_pos[0]][step_pos[1]][forsee_action] - Q_matrix[current_pos[0]][current_pos[1]][step_action])\n",
    "            current_pos = step_pos\n",
    "    return Q_matrix\n",
    "\n",
    "def Q_learning(epochs):\n",
    "    Q_matrix = [[[0.0 for _ in range(4)] for _ in range(world_width)] for _ in range(world_height)]\n",
    "    for row in range(world_height):\n",
    "        for column in range(world_width):\n",
    "            if row==0:\n",
    "                Q_matrix[row][column][0] = -sys.maxsize - 1\n",
    "            if row==world_height-1:\n",
    "                Q_matrix[row][column][1] = -sys.maxsize - 1\n",
    "            if column==0:\n",
    "                Q_matrix[row][column][2] = -sys.maxsize - 1\n",
    "            if column==world_width-1:\n",
    "                Q_matrix[row][column][3] = -sys.maxsize - 1\n",
    "    for epoch in range(epochs):\n",
    "        current_pos = start_pos\n",
    "        while current_pos != end_pos:\n",
    "            step_action = next_action(current_pos, Q_matrix, epsilon)\n",
    "            step_pos = next_pos(current_pos, step_action)\n",
    "            step_reward = get_reward(step_pos)\n",
    "            if step_pos[0] == world_height-1 and 0 < step_pos[1] < world_width-1:\n",
    "                step_pos = start_pos\n",
    "            forsee_action = next_action(step_pos, Q_matrix)\n",
    "            Q_matrix[current_pos[0]][current_pos[1]][step_action] += alpha * (step_reward + gamma * Q_matrix[step_pos[0]][step_pos[1]][forsee_action] - Q_matrix[current_pos[0]][current_pos[1]][step_action])\n",
    "            current_pos = step_pos\n",
    "    return Q_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0)->(3, 0)->(3, 1)->(3, 2)->(3, 3)->(3, 4)->(3, 5)->(3, 6)->(3, 7)->(3, 8)->(3, 9)->(4, 9)\n",
      "(4, 0)->(3, 0)->(3, 1)->(3, 2)->(3, 3)->(3, 4)->(3, 5)->(3, 6)->(3, 7)->(3, 8)->(3, 9)->(4, 9)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    Sarsa_policy = Sarsa(epochs)\n",
    "    show_policy(Sarsa_policy)\n",
    "    Q_learning_policy = Q_learning(epochs)\n",
    "    show_policy(Q_learning_policy)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
